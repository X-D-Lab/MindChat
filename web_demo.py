import gradio as gr
import torch
import torch.nn as nn
from modelscope import Model, snapshot_download
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.generation.utils import GenerationConfig

model_dir = snapshot_download("X-D-Lab/MindChat-Baichuan-13B",
                              revision='v1.0.0')

tokenizer = AutoTokenizer.from_pretrained(model_dir,
                                          use_fast=False,
                                          trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_dir,
                                             device_map="auto",
                                             torch_dtype=torch.float16,
                                             trust_remote_code=True)
model.generation_config = GenerationConfig.from_pretrained(model_dir)


def clear_session():
    return []


def predict(input, history):
    if history is None:
        history = []
    model_input = []
    for chat in history:
        model_input.append({"role": "user", "content": chat[0]})
        model_input.append({"role": "assistant", "content": chat[1]})
    model_input.append({"role": "user", "content": input})
    print(model_input)
    response = model.chat(tokenizer, model_input)
    history.append((input, response))
    history = history[-20:]
    return '', history


block = gr.Blocks()

with block as demo:
    gr.Markdown("""<h1><center>MindChat-13B</center></h1>
     <center>MindChat-13Bï¼šæ¼«è°ˆå¿ƒç†å¤§æ¨¡å‹ï¼ŒæœŸæœ›é€šè¿‡è‡ªèº«çš„åŠªåŠ›å’Œä¸“ä¸šçŸ¥è¯†, åœ¨ä¸¥æ ¼ä¿æŠ¤ç”¨æˆ·éšç§çš„å‰æä¸‹, å…¨æ—¶æ®µå…¨å¤©å€™ä¸ºç”¨æˆ·æä¾›å…¨é¢çš„å¿ƒç†æ”¯æŒå’Œè¯Šç–—å¸®åŠ©, åŒæ—¶å®ç°è‡ªæˆ‘æˆé•¿å’Œå‘å±•, ä»¥æœŸä¸ºå»ºè®¾ä¸€ä¸ªæ›´åŠ å¥åº·ã€åŒ…å®¹å’Œå¹³ç­‰çš„ç¤¾ä¼šè´¡çŒ®åŠ›é‡.</center>
    """)
    chatbot = gr.Chatbot(label='MindChat-13B')
    message = gr.Textbox()
    message.submit(predict,
                   inputs=[message, chatbot],
                   outputs=[message, chatbot])
    with gr.Row():
        clear_history = gr.Button("ğŸ§¹ æ¸…é™¤å†å²å¯¹è¯")
        send = gr.Button("ğŸš€ å‘é€")

    send.click(predict, inputs=[message, chatbot], outputs=[message, chatbot])
    clear_history.click(fn=clear_session,
                        inputs=[],
                        outputs=[chatbot],
                        queue=False)

demo.queue().launch(height=800, share=False)
